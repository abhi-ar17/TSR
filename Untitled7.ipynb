{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi-ar17/TSR/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8HtvNn6SG_LM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as zpimg\n",
        "\n",
        "img = cv2.imread('sign.jpeg')\n",
        "imgee = cv2.imread('sign.jpeg',0)\n",
        "\n",
        "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
        "lowerRange= np.array([0,100,100]) \n",
        "upperRange= np.array([10,255,255]) \n",
        "lowerBound= np.array([160,100,100])\n",
        "upperBound= np.array([179,255,255])\n",
        " \n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
        "#create mask\n",
        "height,width = imgee.shape\n",
        "mask=np.zeros((height,width),np.uint8)\n",
        "\n",
        "#to change size of the image\n",
        "image = cv2.resize(img,(360,240))\n",
        "\n",
        "#object=cv2.inRange(hsv,lowerRange,upperRange)\n",
        "object=cv2.inRange(hsv,lowerBound,upperBound)\n",
        "#it allows pixels within range and black out other\n",
        "cv2.imshow('first',thresh)\n",
        "edged=cv2.Canny(object,30,150)\n",
        "\n",
        "contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "for c in contours:\n",
        "\tprint (c)\n",
        "\tbreak;\n",
        "\n",
        "final=cv2.drawContours(img,contours,0,(255,0,0),0)\n",
        "cv2.imshow('wrw',final)\n",
        "object1=cv2.inRange(img,(255,0,0),(255,0,0))\n",
        "cv2.imshow('object1',object1)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
        "edged1=cv2.Canny(thresh,100,200)\n",
        "cv2.imshow('Edge',edged1)\n",
        "\n",
        "circles=cv2.HoughCircles(edged1,cv2.HOUGH_GRADIENT,1,50,param1=50,param2=20,minRadius=50,maxRadius=750)\n",
        "for i in circles[0,:]:\n",
        "\ti[2]=i[2]+4\n",
        "\t\t#draw on mask\n",
        "\tcv2.circle(mask,(i[0],i[1]),i[2],(255,255,255),-1)\n",
        "#copy that image using that mask\n",
        "masked_data=cv2.bitwise_and(img,img,mask=mask)\n",
        "\n",
        "#apply threshold\n",
        "_,thresh = cv2.threshold(mask,1,255,cv2.THRESH_BINARY)\n",
        "\n",
        "#Find Contour\n",
        "cnts,_=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "x,y,w,h =cv2.boundingRect(contours[0])\n",
        "\n",
        "#crop masked data\n",
        "crop=masked_data[y:y+h,x:x+w]\n",
        "\n",
        "\n",
        "#cv2.rectangle(img,(83,64),(150,170),(0,255,0),3)\n",
        "cv2.imshow('orginal',img)\n",
        "cv2.imshow('HSV',hsv)\n",
        "cv2.imshow('CROP',crop)\n",
        "cv2.imshow('mask', object)\n",
        "cv2.imshow('edged',edged)\n",
        "cv2.imshow('thresh',thresh)\n",
        "cv2.imshow('object2',object1)\n",
        "\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAveCdVQg9Ep",
        "colab_type": "code",
        "outputId": "354a560f-b5bc-4cb9-b43a-baff8822feed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "# Image Classification\n",
        "\n",
        "# Import libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initalize CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Add 2 convolution layers\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# Add pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add 2 more convolution layers\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# Add max pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add 2 more convolution layers\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# Add max pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add global average pooling layer\n",
        "classifier.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Add full connection\n",
        "classifier.add(Dense(units=15, activation='softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit CNN to images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('fdtju/datasets',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'sw/valid',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "classifier.fit_generator(\n",
        "        train_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=5,\n",
        "        validation_data=test_set,\n",
        "        validation_steps=40)\n",
        "\n",
        "classifier.save('model_categorical_complex.model')\n",
        "\n",
        "# Test accuracy of classifier\n",
        "def test_accuracy(classifier, test_set, steps):\n",
        "    num_correct = 0\n",
        "    num_guesses = 0\n",
        "    for i in range(steps):\n",
        "        a = test_set.next()\n",
        "        guesses = classifier.predict(a[0])\n",
        "        correct = a[1]\n",
        "        for index in range(len(guesses)):\n",
        "            num_guesses += 1\n",
        "            if round(guesses[index][0]) == correct[index]:\n",
        "                num_correct += 1\n",
        "    return num_correct, num_guesses\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11884 images belonging to 15 classes.\n",
            "Found 4308 images belonging to 15 classes.\n",
            "Epoch 1/5\n",
            "100/100 [==============================] - 16s 165ms/step - loss: 2.3025 - acc: 0.2047 - val_loss: 1.7847 - val_acc: 0.3648\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.8360 - acc: 0.3841 - val_loss: 1.6251 - val_acc: 0.3703\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 1.5479 - acc: 0.4872 - val_loss: 1.2935 - val_acc: 0.5773\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 1.2620 - acc: 0.6042 - val_loss: 1.0847 - val_acc: 0.6191\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.9742 - acc: 0.6794 - val_loss: 0.7796 - val_acc: 0.7602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXesHeLoEUFE",
        "colab_type": "code",
        "outputId": "e9f74212-77de-4864-b82a-b9b1b2211068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "\n",
        "\n",
        "a=[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "fifty=np.asarray(a)\n",
        "\n",
        "b=[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "seventy=np.asarray(b)\n",
        "\n",
        "c=[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "Cattle=np.asarray(c)\n",
        "\n",
        "d=[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "Hump=np.asarray(d)\n",
        "\n",
        "e=[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "Men=np.asarray(e)\n",
        "\n",
        "f=[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "Narrow=np.asarray(f)\n",
        "\n",
        "g=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "No_Paraking=np.asarray(g)\n",
        "\n",
        "h=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "No_left=np.asarray(h)\n",
        "\n",
        "i=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "No_right=np.asarray(i)\n",
        "\n",
        "j=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "No_stop=np.asarray(j)\n",
        "\n",
        "k=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n",
        "Noentry=np.asarray(k)\n",
        "\n",
        "l=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
        "Pedestrian=np.asarray(l)\n",
        "\n",
        "m=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]\n",
        "Stop=np.asarray(m)\n",
        "\n",
        "n=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]]\n",
        "Two=np.asarray(n)\n",
        "\n",
        "o=[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]\n",
        "school=np.asarray(o)\n",
        "\n",
        "#DATADIR = \"fdtju/datasets\"\n",
        "\n",
        "#CATEGORIES =[\"70\",\"50\",\"Cattle\",\"Narrow\",\"No_left\",\"No_Parking\",\"No_right\",\"No_stop\",\"Pedestrian\",\"school\",\"Stop\",\"Two\" ,\"Hump\", \"Men\",\"Noentry\"]\n",
        "\n",
        "def prepare(filepath):\n",
        "\tIMG_SIZE=64\n",
        "\timg_array = cv2.imread(filepath)\n",
        "\tnew_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "\treturn new_array.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "\n",
        "model=tf.keras.models.load_model(\"model_categorical_complex.model\")\n",
        "\n",
        "prediction = model.predict([prepare('Cattle_010.jpg')])\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "if((prediction==fifty).all()):\n",
        "    song = AudioSegment.from_wav(\"50.wav\")\n",
        "    play(song)\n",
        "elif((prediction==seventy).all()):\n",
        "    song = AudioSegment.from_wav(\"70.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Cattle).all()):\n",
        "    song = AudioSegment.from_wav(\"cattle.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Hump).all()):\n",
        "    song = AudioSegment.from_wav(\"hump.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Men).all()):\n",
        "    song = AudioSegment.from_wav(\"men.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Narrow).all()):\n",
        "    song = AudioSegment.from_wav(\"narrow.wav\")\n",
        "    play(song)\n",
        "elif((prediction==No_Parking).all()):\n",
        "  song = AudioSegment.from_wav(\"noparking.wav\")\n",
        "    play(song)\n",
        "elif((prediction==No_left).all()):\n",
        "  song = AudioSegment.from_wav(\"noleft.wav\")\n",
        "    play(song)\n",
        "elif((prediction==No_right).all()):\n",
        "  song = AudioSegment.from_wav(\"noright.wav\")\n",
        "    play(song)\n",
        "elif((prediction==No_stop).all()):\n",
        "  song = AudioSegment.from_wav(\"nostop.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Noentry).all()):\n",
        "  song = AudioSegment.from_wav(\"noentry.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Pedestrian).all()):\n",
        "  song = AudioSegment.from_wav(\"pedestrian.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Stop).all()):\n",
        "  song = AudioSegment.from_wav(\"stop.wav\")\n",
        "    play(song)\n",
        "elif((prediction==Two).all()):\n",
        "  song = AudioSegment.from_wav(\"2.wav\")\n",
        "    play(song)\n",
        "elif((prediction==school).all()):\n",
        "  song = AudioSegment.from_wav(\"school.wav\")\n",
        "    play(song)\n",
        "else :\n",
        "    print(\"abd\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tibrc98aHY5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "39939228-dd5b-474f-bb3a-9e27c9b5cf38"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install pydub"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tP41F1bD2FI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c1136cd9-e6f4-4e72-8db1-7bfdd74f8290"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abhi-ar17/fdtju"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fdtju'...\n",
            "remote: Enumerating objects: 1092, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/1092)   \u001b[K\rremote: Counting objects:   1% (11/1092)   \u001b[K\rremote: Counting objects:   2% (22/1092)   \u001b[K\rremote: Counting objects:   3% (33/1092)   \u001b[K\rremote: Counting objects:   4% (44/1092)   \u001b[K\rremote: Counting objects:   5% (55/1092)   \u001b[K\rremote: Counting objects:   6% (66/1092)   \u001b[K\rremote: Counting objects:   7% (77/1092)   \u001b[K\rremote: Counting objects:   8% (88/1092)   \u001b[K\rremote: Counting objects:   9% (99/1092)   \u001b[K\rremote: Counting objects:  10% (110/1092)   \u001b[K\rremote: Counting objects:  11% (121/1092)   \u001b[K\rremote: Counting objects:  12% (132/1092)   \u001b[K\rremote: Counting objects:  13% (142/1092)   \u001b[K\rremote: Counting objects:  14% (153/1092)   \u001b[K\rremote: Counting objects:  15% (164/1092)   \u001b[K\rremote: Counting objects:  16% (175/1092)   \u001b[K\rremote: Counting objects:  17% (186/1092)   \u001b[K\rremote: Counting objects:  18% (197/1092)   \u001b[K\rremote: Counting objects:  19% (208/1092)   \u001b[K\rremote: Counting objects:  20% (219/1092)   \u001b[K\rremote: Counting objects:  21% (230/1092)   \u001b[K\rremote: Counting objects:  22% (241/1092)   \u001b[K\rremote: Counting objects:  23% (252/1092)   \u001b[K\rremote: Counting objects:  24% (263/1092)   \u001b[K\rremote: Counting objects:  25% (273/1092)   \u001b[K\rremote: Counting objects:  26% (284/1092)   \u001b[K\rremote: Counting objects:  27% (295/1092)   \u001b[K\rremote: Counting objects:  28% (306/1092)   \u001b[K\rremote: Counting objects:  29% (317/1092)   \u001b[K\rremote: Counting objects:  30% (328/1092)   \u001b[K\rremote: Counting objects:  31% (339/1092)   \u001b[K\rremote: Counting objects:  32% (350/1092)   \u001b[K\rremote: Counting objects:  33% (361/1092)   \u001b[K\rremote: Counting objects:  34% (372/1092)   \u001b[K\rremote: Counting objects:  35% (383/1092)   \u001b[K\rremote: Counting objects:  36% (394/1092)   \u001b[K\rremote: Counting objects:  37% (405/1092)   \u001b[K\rremote: Counting objects:  38% (415/1092)   \u001b[K\rremote: Counting objects:  39% (426/1092)   \u001b[K\rremote: Counting objects:  40% (437/1092)   \u001b[K\rremote: Counting objects:  41% (448/1092)   \u001b[K\rremote: Counting objects:  42% (459/1092)   \u001b[K\rremote: Counting objects:  43% (470/1092)   \u001b[K\rremote: Counting objects:  44% (481/1092)   \u001b[K\rremote: Counting objects:  45% (492/1092)   \u001b[K\rremote: Counting objects:  46% (503/1092)   \u001b[K\rremote: Counting objects:  47% (514/1092)   \u001b[K\rremote: Counting objects:  48% (525/1092)   \u001b[K\rremote: Counting objects:  49% (536/1092)   \u001b[K\rremote: Counting objects:  50% (546/1092)   \u001b[K\rremote: Counting objects:  51% (557/1092)   \u001b[K\rremote: Counting objects:  52% (568/1092)   \u001b[K\rremote: Counting objects:  53% (579/1092)   \u001b[K\rremote: Counting objects:  54% (590/1092)   \u001b[K\rremote: Counting objects:  55% (601/1092)   \u001b[K\rremote: Counting objects:  56% (612/1092)   \u001b[K\rremote: Counting objects:  57% (623/1092)   \u001b[K\rremote: Counting objects:  58% (634/1092)   \u001b[K\rremote: Counting objects:  59% (645/1092)   \u001b[K\rremote: Counting objects:  60% (656/1092)   \u001b[K\rremote: Counting objects:  61% (667/1092)   \u001b[K\rremote: Counting objects:  62% (678/1092)   \u001b[K\rremote: Counting objects:  63% (688/1092)   \u001b[K\rremote: Counting objects:  64% (699/1092)   \u001b[K\rremote: Counting objects:  65% (710/1092)   \u001b[K\rremote: Counting objects:  66% (721/1092)   \u001b[K\rremote: Counting objects:  67% (732/1092)   \u001b[K\rremote: Counting objects:  68% (743/1092)   \u001b[K\rremote: Counting objects:  69% (754/1092)   \u001b[K\rremote: Counting objects:  70% (765/1092)   \u001b[K\rremote: Counting objects:  71% (776/1092)   \u001b[K\rremote: Counting objects:  72% (787/1092)   \u001b[K\rremote: Counting objects:  73% (798/1092)   \u001b[K\rremote: Counting objects:  74% (809/1092)   \u001b[K\rremote: Counting objects:  75% (819/1092)   \u001b[K\rremote: Counting objects:  76% (830/1092)   \u001b[K\rremote: Counting objects:  77% (841/1092)   \u001b[K\rremote: Counting objects:  78% (852/1092)   \u001b[K\rremote: Counting objects:  79% (863/1092)   \u001b[K\rremote: Counting objects:  80% (874/1092)   \u001b[K\rremote: Counting objects:  81% (885/1092)   \u001b[K\rremote: Counting objects:  82% (896/1092)   \u001b[K\rremote: Counting objects:  83% (907/1092)   \u001b[K\rremote: Counting objects:  84% (918/1092)   \u001b[K\rremote: Counting objects:  85% (929/1092)   \u001b[K\rremote: Counting objects:  86% (940/1092)   \u001b[K\rremote: Counting objects:  87% (951/1092)   \u001b[K\rremote: Counting objects:  88% (961/1092)   \u001b[K\rremote: Counting objects:  89% (972/1092)   \u001b[K\rremote: Counting objects:  90% (983/1092)   \u001b[K\rremote: Counting objects:  91% (994/1092)   \u001b[K\rremote: Counting objects:  92% (1005/1092)   \u001b[K\rremote: Counting objects:  93% (1016/1092)   \u001b[K\rremote: Counting objects:  94% (1027/1092)   \u001b[K\rremote: Counting objects:  95% (1038/1092)   \u001b[K\rremote: Counting objects:  96% (1049/1092)   \u001b[K\rremote: Counting objects:  97% (1060/1092)   \u001b[K\rremote: Counting objects:  98% (1071/1092)   \u001b[K\rremote: Counting objects:  99% (1082/1092)   \u001b[K\rremote: Counting objects: 100% (1092/1092)   \u001b[K\rremote: Counting objects: 100% (1092/1092), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1075/1075), done.\u001b[K\n",
            "remote: Total 1092 (delta 16), reused 1092 (delta 16), pack-reused 0\n",
            "Receiving objects: 100% (1092/1092), 23.51 MiB | 53.14 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "Checking out files: 100% (11884/11884), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tbGEFnrM2Nl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c61f6eea-ae4c-4f7b-bb40-3364fc84f6e8"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abhi-ar17/sw"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sw'...\n",
            "remote: Enumerating objects: 1092, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/1092)   \u001b[K\rremote: Counting objects:   1% (11/1092)   \u001b[K\rremote: Counting objects:   2% (22/1092)   \u001b[K\rremote: Counting objects:   3% (33/1092)   \u001b[K\rremote: Counting objects:   4% (44/1092)   \u001b[K\rremote: Counting objects:   5% (55/1092)   \u001b[K\rremote: Counting objects:   6% (66/1092)   \u001b[K\rremote: Counting objects:   7% (77/1092)   \u001b[K\rremote: Counting objects:   8% (88/1092)   \u001b[K\rremote: Counting objects:   9% (99/1092)   \u001b[K\rremote: Counting objects:  10% (110/1092)   \u001b[K\rremote: Counting objects:  11% (121/1092)   \u001b[K\rremote: Counting objects:  12% (132/1092)   \u001b[K\rremote: Counting objects:  13% (142/1092)   \u001b[K\rremote: Counting objects:  14% (153/1092)   \u001b[K\rremote: Counting objects:  15% (164/1092)   \u001b[K\rremote: Counting objects:  16% (175/1092)   \u001b[K\rremote: Counting objects:  17% (186/1092)   \u001b[K\rremote: Counting objects:  18% (197/1092)   \u001b[K\rremote: Counting objects:  19% (208/1092)   \u001b[K\rremote: Counting objects:  20% (219/1092)   \u001b[K\rremote: Counting objects:  21% (230/1092)   \u001b[K\rremote: Counting objects:  22% (241/1092)   \u001b[K\rremote: Counting objects:  23% (252/1092)   \u001b[K\rremote: Counting objects:  24% (263/1092)   \u001b[K\rremote: Counting objects:  25% (273/1092)   \u001b[K\rremote: Counting objects:  26% (284/1092)   \u001b[K\rremote: Counting objects:  27% (295/1092)   \u001b[K\rremote: Counting objects:  28% (306/1092)   \u001b[K\rremote: Counting objects:  29% (317/1092)   \u001b[K\rremote: Counting objects:  30% (328/1092)   \u001b[K\rremote: Counting objects:  31% (339/1092)   \u001b[K\rremote: Counting objects:  32% (350/1092)   \u001b[K\rremote: Counting objects:  33% (361/1092)   \u001b[K\rremote: Counting objects:  34% (372/1092)   \u001b[K\rremote: Counting objects:  35% (383/1092)   \u001b[K\rremote: Counting objects:  36% (394/1092)   \u001b[K\rremote: Counting objects:  37% (405/1092)   \u001b[K\rremote: Counting objects:  38% (415/1092)   \u001b[K\rremote: Counting objects:  39% (426/1092)   \u001b[K\rremote: Counting objects:  40% (437/1092)   \u001b[K\rremote: Counting objects:  41% (448/1092)   \u001b[K\rremote: Counting objects:  42% (459/1092)   \u001b[K\rremote: Counting objects:  43% (470/1092)   \u001b[K\rremote: Counting objects:  44% (481/1092)   \u001b[K\rremote: Counting objects:  45% (492/1092)   \u001b[K\rremote: Counting objects:  46% (503/1092)   \u001b[K\rremote: Counting objects:  47% (514/1092)   \u001b[K\rremote: Counting objects:  48% (525/1092)   \u001b[K\rremote: Counting objects:  49% (536/1092)   \u001b[K\rremote: Counting objects:  50% (546/1092)   \u001b[K\rremote: Counting objects:  51% (557/1092)   \u001b[K\rremote: Counting objects:  52% (568/1092)   \u001b[K\rremote: Counting objects:  53% (579/1092)   \u001b[K\rremote: Counting objects:  54% (590/1092)   \u001b[K\rremote: Counting objects:  55% (601/1092)   \u001b[K\rremote: Counting objects:  56% (612/1092)   \u001b[K\rremote: Counting objects:  57% (623/1092)   \u001b[K\rremote: Counting objects:  58% (634/1092)   \u001b[K\rremote: Counting objects:  59% (645/1092)   \u001b[K\rremote: Counting objects:  60% (656/1092)   \u001b[K\rremote: Counting objects:  61% (667/1092)   \u001b[K\rremote: Counting objects:  62% (678/1092)   \u001b[K\rremote: Counting objects:  63% (688/1092)   \u001b[K\rremote: Counting objects:  64% (699/1092)   \u001b[K\rremote: Counting objects:  65% (710/1092)   \u001b[K\rremote: Counting objects:  66% (721/1092)   \u001b[K\rremote: Counting objects:  67% (732/1092)   \u001b[K\rremote: Counting objects:  68% (743/1092)   \u001b[K\rremote: Counting objects:  69% (754/1092)   \u001b[K\rremote: Counting objects:  70% (765/1092)   \u001b[K\rremote: Counting objects:  71% (776/1092)   \u001b[K\rremote: Counting objects:  72% (787/1092)   \u001b[K\rremote: Counting objects:  73% (798/1092)   \u001b[K\rremote: Counting objects:  74% (809/1092)   \u001b[K\rremote: Counting objects:  75% (819/1092)   \u001b[K\rremote: Counting objects:  76% (830/1092)   \u001b[K\rremote: Counting objects:  77% (841/1092)   \u001b[K\rremote: Counting objects:  78% (852/1092)   \u001b[K\rremote: Counting objects:  79% (863/1092)   \u001b[K\rremote: Counting objects:  80% (874/1092)   \u001b[K\rremote: Counting objects:  81% (885/1092)   \u001b[K\rremote: Counting objects:  82% (896/1092)   \u001b[K\rremote: Counting objects:  83% (907/1092)   \u001b[K\rremote: Counting objects:  84% (918/1092)   \u001b[K\rremote: Counting objects:  85% (929/1092)   \u001b[K\rremote: Counting objects:  86% (940/1092)   \u001b[K\rremote: Counting objects:  87% (951/1092)   \u001b[K\rremote: Counting objects:  88% (961/1092)   \u001b[K\rremote: Counting objects:  89% (972/1092)   \u001b[K\rremote: Counting objects:  90% (983/1092)   \u001b[K\rremote: Counting objects:  91% (994/1092)   \u001b[K\rremote: Counting objects:  92% (1005/1092)   \u001b[K\rremote: Counting objects:  93% (1016/1092)   \u001b[K\rremote: Counting objects:  94% (1027/1092)   \u001b[K\rremote: Counting objects:  95% (1038/1092)   \u001b[K\rremote: Counting objects:  96% (1049/1092)   \u001b[K\rremote: Counting objects:  97% (1060/1092)   \u001b[K\rremote: Counting objects:  98% (1071/1092)   \u001b[K\rremote: Counting objects:  99% (1082/1092)   \u001b[K\rremote: Counting objects: 100% (1092/1092)   \u001b[K\rremote: Counting objects: 100% (1092/1092), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1075/1075), done.\u001b[K\n",
            "remote: Total 1092 (delta 16), reused 1092 (delta 16), pack-reused 0\n",
            "Receiving objects: 100% (1092/1092), 23.49 MiB | 53.46 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MuatJpF3Gt5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}